{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from utils import generate_and_save_eeg_for_all_images\n",
    "import torch\n",
    "from mne.time_frequency import psd_array_multitaper\n",
    "import os\n",
    "import torch.nn.functional as F\n",
    "from scipy.signal import spectrogram\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.special import softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda:1\" if torch.cuda.is_available() else \"cpu\"\n",
    "fs = 250\n",
    "selected_channel_idxes = [3, 4, 5] # 'O1', 'Oz', 'O2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sub-08 get target eeg and psd\n",
    "model_path = '/mnt/repo0/kyw/close-loop/sub_encoder_alexnet/sub-08/model_state_dict.pt'\n",
    "lowest_path = ['/mnt/repo0/kyw/images_set/test_images/00183_tick/tick_06s.jpg']\n",
    "save_path = '/mnt/repo0/kyw/close-loop/modulation'\n",
    "label = ['target']\n",
    "# generate_and_save_eeg_for_all_images(model_path, lowest_path, save_path, device, label)\n",
    "target_path = '/mnt/repo0/kyw/close-loop/modulation/target_1.npy'\n",
    "target_signal = np.load(target_path, allow_pickle=True)\n",
    "selected_target_signal = target_signal[selected_channel_idxes, :]\n",
    "target_psd, target_freqs = psd_array_multitaper(selected_target_signal, fs, adaptive=True, normalization='full', verbose=0) # psd(3, 126)\n",
    "target_psd = torch.from_numpy(target_psd.flatten())\n",
    "target_psd = target_psd.unsqueeze(0)\n",
    "# print(target_psd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_image_pool(image_set_path):\n",
    "    test_images_path = []\n",
    "    labels = []\n",
    "    for sub_test_image in sorted(os.listdir(image_set_path)):\n",
    "        if sub_test_image.startswith('.'):\n",
    "            continue\n",
    "        sub_image_path = os.path.join(image_set_path, sub_test_image)\n",
    "        for image in sorted(os.listdir(sub_image_path)):\n",
    "            if image.startswith('.'):\n",
    "                continue\n",
    "            image_label = os.path.splitext(image)[0]\n",
    "            labels.append(image_label)\n",
    "            image_path = os.path.join(sub_image_path, image)\n",
    "            test_images_path.append(image_path)\n",
    "    return test_images_path, labels \n",
    "image_set_path = '/mnt/repo0/kyw/images_set/test_images'\n",
    "test_images_path, _ = get_image_pool(image_set_path)\n",
    "target_path = '/mnt/repo0/kyw/images_set/test_images/00183_tick/tick_06s.jpg'\n",
    "test_images_path.remove(target_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_avg_signal(signal, name, save_path):\n",
    "    average_signals = np.mean(signal, axis=0)\n",
    "    plt.figure(figsize=(10, 3))\n",
    "    plt.plot(average_signals)\n",
    "    plt.title('Average Signal')\n",
    "    plt.xlabel('Time (samples)')\n",
    "    plt.ylabel('Amplitude')\n",
    "    plt.grid()\n",
    "    plt.savefig(save_path + f'{name}_avg_signal.jpg')\n",
    "    plt.show()\n",
    "    return average_signals\n",
    "\n",
    "def get_time_freq(average_signals, fs, name, save_path):\n",
    "    frequencies, times, Sxx = spectrogram(average_signals, fs, nperseg=50)\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.pcolormesh(times, frequencies, 10 * np.log10(Sxx + 1e-10), shading='gouraud')\n",
    "    plt.ylabel('Frequency (Hz)')\n",
    "    plt.xlabel('Time (s)')\n",
    "    plt.title('Time-Frequency')\n",
    "    plt.colorbar(label='Intensity (dB)')\n",
    "    plt.ylim(0, fs / 2)\n",
    "    plt.savefig(save_path + f'{name}_time_freq.jpg')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_eeg_pool(gene_eeg):\n",
    "    eeg_paths = []\n",
    "    for eeg in sorted(os.listdir(gene_eeg)):\n",
    "        eeg_path = os.path.join(gene_eeg, eeg)\n",
    "        eeg_paths.append(eeg_path)\n",
    "    return eeg_paths\n",
    "gene_eeg = '/mnt/repo0/kyw/close-loop/sub_encoder_alexnet_test/sub-08'\n",
    "eeg_paths = get_eeg_pool(gene_eeg)\n",
    "target_eeg = '/mnt/repo0/kyw/close-loop/sub_encoder_alexnet_test/sub-08/00183_tick_183.npy'\n",
    "eeg_paths.remove(target_eeg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.9245198083818775, 0.8688719949912524] ['/mnt/repo0/kyw/images_set/test_images/00107_lampshade/lampshade_05s.jpg', '/mnt/repo0/kyw/images_set/test_images/00189_tube_top/tube_top_11s.jpg'] ['/mnt/repo0/kyw/close-loop/sub_encoder_alexnet_test/sub-08/00107_lampshade_107.npy', '/mnt/repo0/kyw/close-loop/sub_encoder_alexnet_test/sub-08/00189_tube_top_189.npy']\n"
     ]
    }
   ],
   "source": [
    "def get_prob_random_sample(test_images_path, eeg_paths, fs, selected_channel_idxes, processed_paths):\n",
    "    available_paths = [path for path in test_images_path if path not in processed_paths]\n",
    "    sample_image_paths = random.sample(available_paths, 10)\n",
    "    processed_paths.update(sample_image_paths)\n",
    "    idxes = [test_images_path.index(path) for path in sample_image_paths]\n",
    "    sample_eeg_paths = [eeg_paths[idx] for idx in idxes]\n",
    "    similarities = []\n",
    "    for sample_eeg_path in sample_eeg_paths:\n",
    "        sample_eeg = np.load(sample_eeg_path, allow_pickle=True)\n",
    "        selected_eeg = sample_eeg[selected_channel_idxes, :]\n",
    "        psd, _ = psd_array_multitaper(selected_eeg, fs, adaptive=True, normalization='full', verbose=0)\n",
    "        psd = torch.from_numpy(psd.flatten())\n",
    "        psd = psd.unsqueeze(0)\n",
    "        sim = F.cosine_similarity(target_psd, psd)\n",
    "        similarities.append(sim.item())\n",
    "    probabilities = softmax(similarities)\n",
    "    chosen_indices = np.random.choice(len(probabilities), size=2, p=probabilities)\n",
    "    chosen_similarities = [similarities[idx] for idx in chosen_indices.tolist()] \n",
    "    chosen_image_paths = [sample_image_paths[idx] for idx in chosen_indices.tolist()]\n",
    "    chosen_eeg_paths = [sample_eeg_paths[idx] for idx in chosen_indices.tolist()]\n",
    "    return chosen_similarities, chosen_image_paths, chosen_eeg_paths\n",
    "processed_paths = set()\n",
    "chosen_similarities, chosen_image_paths, chosen_eeg_paths = get_prob_random_sample(test_images_path, eeg_paths, fs, selected_channel_idxes, processed_paths)\n",
    "print(chosen_similarities, chosen_image_paths, chosen_eeg_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_prob_sample(test_images_path, eeg_paths, fs, selected_channel_idxes, processed_paths):\n",
    "    available_paths = [path for path in test_images_path if path not in processed_paths]\n",
    "    sample_image_paths = random.sample(available_paths, 10)\n",
    "    idxes = [test_images_path.index(path) for path in sample_image_paths]\n",
    "    sample_eeg_paths = [eeg_paths[idx] for idx in idxes]\n",
    "    print(idxes)\n",
    "    print(sample_image_paths, sample_eeg_paths)\n",
    "\n",
    "    similarities = []\n",
    "    for sample_eeg_path in sample_eeg_paths:\n",
    "        sample_eeg = np.load(sample_eeg_path, allow_pickle=True)\n",
    "        selected_eeg = sample_eeg[selected_channel_idxes, :]\n",
    "        psd, _ = psd_array_multitaper(selected_eeg, fs, adaptive=True, normalization='full', verbose=0)\n",
    "        psd = torch.from_numpy(psd.flatten())\n",
    "        psd = psd.unsqueeze(0)\n",
    "        sim = F.cosine_similarity(target_psd, psd)\n",
    "        similarities.append(sim.item())\n",
    "    print(similarities)\n",
    "    probabilities = softmax(similarities)\n",
    "    print(probabilities)\n",
    "    top_indices = np.argsort(probabilities)[-1:] \n",
    "    top_similarity = [similarities[i] for i in top_indices]\n",
    "    top_original_indices = [idxes[i] for i in top_indices]\n",
    "    top_eeg_paths = [sample_eeg_paths[i] for i in top_indices]\n",
    "    top_image_paths = [sample_image_paths[i] for i in top_indices]\n",
    "\n",
    "    remaining_indices = np.setdiff1d(np.arange(len(probabilities)), top_indices)\n",
    "    print(remaining_indices)\n",
    "    remaining_probs = probabilities[remaining_indices] / probabilities[remaining_indices].sum()\n",
    "    print(remaining_probs)\n",
    "    chosen_index = np.random.choice(remaining_indices, p=remaining_probs)\n",
    "    chosen_original_index = idxes[chosen_index]\n",
    "    chosen_eeg_path = sample_eeg_paths[chosen_index]\n",
    "    chosen_image_path = sample_image_paths[chosen_index]\n",
    "    chosen_similarity = similarities[chosen_index]\n",
    "    print('chosen_index:', chosen_index)\n",
    "    print(\"Chosen original index:\", chosen_original_index)\n",
    "    print(\"Chosen sample path:\", chosen_eeg_path)\n",
    "    print(\"Chosen image path:\", chosen_image_path)\n",
    "    print('chosen_similarity:', chosen_similarity)\n",
    "    processed_paths.update(sample_image_paths)\n",
    "    return list(zip(top_original_indices, top_similarity)) + [(chosen_original_index, chosen_similarity)], top_eeg_paths, processed_paths, top_image_paths, chosen_eeg_path, chosen_image_path\n",
    "# processed_paths = set()\n",
    "# pair_cs, top_eeg_paths, processed_paths, top_image_paths, chosen_eeg_path, chosen_image_path= get_prob_sample(test_images_path, eeg_paths, fs, selected_channel_idxes, processed_paths)\n",
    "# print(pair_cs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# new_cs = []\n",
    "# for top_sample_path in top_sample_paths:\n",
    "#     eeg = np.load(top_sample_path, allow_pickle=True)\n",
    "#     selected_eeg = eeg[selected_channel_idxes, :]\n",
    "#     psd, _ = psd_array_multitaper(selected_eeg, fs, adaptive=True, normalization='full', verbose=0)\n",
    "#     psd = torch.from_numpy(psd.flatten())\n",
    "#     psd = psd.unsqueeze(0)\n",
    "#     sim = F.cosine_similarity(target_psd, psd)\n",
    "#     new_cs.append(sim.item())\n",
    "#     print(sim)\n",
    "# print(new_cs)\n",
    "\n",
    "# new_cs = []\n",
    "# for _, similarity in pair_cs:\n",
    "#     new_cs.append(float(similarity)) \n",
    "# print(new_cs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_928895/1909085304.py:12: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model_state_dict = torch.load(model_weights_path, map_location=device)\n",
      "/tmp/ipykernel_928895/1909085304.py:17: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(diffusion_model_path, map_location=device)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "73755f8feaf448c8914adf3300be8e40",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading pipeline components...:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from PIL import Image\n",
    "from custom_pipeline_tjh import *\n",
    "from diffusion_prior_tjh import *\n",
    "import open_clip\n",
    "from utils import Proj_img\n",
    "\n",
    "vlmodel, preprocess_train, feature_extractor = open_clip.create_model_and_transforms(\n",
    "    model_name = 'ViT-H-14', pretrained = None, precision='fp32', device=device\n",
    ")\n",
    "\n",
    "model_weights_path = \"/mnt/repo0/kyw/open_clip_pytorch_model.bin\"\n",
    "model_state_dict = torch.load(model_weights_path, map_location=device)\n",
    "vlmodel.load_state_dict(model_state_dict)\n",
    "vlmodel.eval()\n",
    "\n",
    "diffusion_model_path = \"/mnt/repo0/kyw/close-loop/sub_model/sub-08/diffusion_250hz/ATM_S_reconstruction_scale_0_1000_40.pth\"\n",
    "checkpoint = torch.load(diffusion_model_path, map_location=device)\n",
    "img_model = Proj_img() \n",
    "img_model.load_state_dict(checkpoint['img_model_state_dict'])\n",
    "generator = Generator4Embeds(num_inference_steps=4, device=device, guidance_scale=2.0)\n",
    "\n",
    "# def image_to_images(image_gt_path, num_images, device, num_round, file_name):\n",
    "#     img_model.eval()\n",
    "#     gt_image_input = torch.stack([preprocess_train(Image.open(image_gt_path).convert(\"RGB\"))]).to(device)\n",
    "#     vlmodel.to(device)\n",
    "#     img_embeds = vlmodel.encode_image(gt_image_input)\n",
    "#     save_img_path = f'/mnt/repo0/kyw/close-loop/loop_random/loop{num_round}'\n",
    "#     os.makedirs(save_img_path, exist_ok=True)\n",
    "#     batch_size = 2 \n",
    "#     for batch_start in range(0, num_images, batch_size):\n",
    "#         batch_images = []\n",
    "#         for idx in range(batch_start, min(batch_start + batch_size, num_images)):\n",
    "#             with torch.no_grad(): \n",
    "#                 image = generator.generate(img_embeds, guidance_scale=5.0)\n",
    "#             save_imgs_path = os.path.join(save_img_path, f'{file_name}_{idx}.jpg') \n",
    "#             image.save(save_imgs_path)\n",
    "#             print(f\"图片保存至: {save_imgs_path}\")\n",
    "#         del batch_images\n",
    "#         torch.cuda.empty_cache()\n",
    "\n",
    "def fusion_image_to_images(image_gt_paths, num_images, device, save_path, scale):\n",
    "    img_model.eval()\n",
    "    img_embeds = []\n",
    "    for image_gt_path in image_gt_paths:\n",
    "        gt_image_input = torch.stack([preprocess_train(Image.open(image_gt_path).convert(\"RGB\"))]).to(device)\n",
    "        vlmodel.to(device)\n",
    "        img_embed = vlmodel.encode_image(gt_image_input)\n",
    "        img_embeds.append(img_embed)\n",
    "\n",
    "    embed1, embed2 = img_embeds[0], img_embeds[1]\n",
    "    embed_len = embed1.size(1)\n",
    "    start_idx = random.randint(0, embed_len - scale - 1)\n",
    "    end_idx = start_idx + scale\n",
    "    temp = embed1[:, start_idx:end_idx].clone()\n",
    "    embed1[:, start_idx:end_idx] = embed2[:, start_idx:end_idx]\n",
    "    embed2[:, start_idx:end_idx] = temp\n",
    "\n",
    "    save_img_path = save_path\n",
    "    os.makedirs(save_img_path, exist_ok=True)\n",
    "    batch_size = 2 \n",
    "    for batch_start in range(0, num_images, batch_size):\n",
    "        batch_images = []\n",
    "        for idx in range(batch_start, min(batch_start + batch_size, num_images)):\n",
    "            with torch.no_grad(): \n",
    "                image = generator.generate(embed1, guidance_scale=2.0)\n",
    "            save_imgs_path = os.path.join(save_img_path, f'{scale}_{idx}.jpg') \n",
    "            image.save(save_imgs_path)\n",
    "            print(f\"图片保存至: {save_imgs_path}\")\n",
    "        del batch_images\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "\n",
    "    # file_name = os.path.basename(top_image_path)\n",
    "    # file_name = os.path.splitext(file_name)[0]\n",
    "    # image_to_images(top_image_path, 2, device, 1, file_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'fusion_image_to_images' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# 1\u001b[39;00m\n\u001b[1;32m      2\u001b[0m save_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/mnt/repo0/kyw/close-loop/loop_random/loop1\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m----> 3\u001b[0m \u001b[43mfusion_image_to_images\u001b[49m(chosen_image_paths, \u001b[38;5;241m4\u001b[39m, device, save_path, \u001b[38;5;241m256\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'fusion_image_to_images' is not defined"
     ]
    }
   ],
   "source": [
    "# 1\n",
    "save_path = '/mnt/repo0/kyw/close-loop/loop_random/loop1'\n",
    "fusion_image_to_images(chosen_image_paths, 4, device, save_path, 256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fusion_image_to_images(top_image_paths, 4, device, 1, 128)\n",
    "fusion_image_to_images(top_image_paths, 4, device, 1, 256)\n",
    "fusion_image_to_images(top_image_paths, 4, device, 1, 512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1\n",
    "image_path_list = []\n",
    "label_list = []\n",
    "for image in sorted(os.listdir(save_path)):\n",
    "    image_path = os.path.join(save_path, image)\n",
    "    new_sample_path.append(image_path)\n",
    "    image_path_list.append(image_path)\n",
    "    file_name = os.path.splitext(image)[0]\n",
    "    label_list.append(file_name)\n",
    "print(new_sample_path)\n",
    "generate_and_save_eeg_for_all_images(model_path, image_path_list, save_path, device, label_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "similarities = []\n",
    "for eeg in sorted(os.listdir(save_path)):\n",
    "    if eeg.endswith('npy'):\n",
    "        eeg_path = os.path.join(save_path, eeg)\n",
    "        print(eeg_path)\n",
    "        file_name = os.path.splitext(eeg)[0]\n",
    "        eeg = np.load(eeg_path, allow_pickle=True)\n",
    "        selected_eeg = eeg[selected_channel_idxes, :]\n",
    "        psd, _ = psd_array_multitaper(selected_eeg, fs, adaptive=True, normalization='full', verbose=0)\n",
    "        psd = torch.from_numpy(psd.flatten())\n",
    "        psd = psd.unsqueeze(0)\n",
    "        sim = F.cosine_similarity(target_psd, psd)\n",
    "        new_cs.append(sim.item())\n",
    "        similarities.append(sim.item())\n",
    "        # average_signals = get_avg_signal(selected_eeg, file_name, 1)\n",
    "        # get_time_freq(average_signals, fs, file_name, 1)\n",
    "print(similarities)\n",
    "print(new_cs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "available_paths = [path for path in test_images_path if path not in processed_paths]\n",
    "print(len(available_paths))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_image_paths = random.sample(available_paths, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for sample_image_path in sample_image_paths:\n",
    "    new_sample_path.append(sample_image_path)\n",
    "print(new_sample_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(new_sample_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_paths.update(sample_image_paths)\n",
    "print(len(processed_paths))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idxes = [test_images_path.index(path) for path in sample_image_paths]\n",
    "sample_eeg_paths = [eeg_paths[idx] for idx in idxes]\n",
    "similarities = []\n",
    "for sample_eeg_path in sample_eeg_paths:\n",
    "    print(sample_eeg_path)\n",
    "    sample_eeg = np.load(sample_eeg_path, allow_pickle=True)\n",
    "    selected_eeg = sample_eeg[selected_channel_idxes, :]\n",
    "    psd, _ = psd_array_multitaper(selected_eeg, fs, adaptive=True, normalization='full', verbose=0)\n",
    "    psd = torch.from_numpy(psd.flatten())\n",
    "    psd = psd.unsqueeze(0)\n",
    "    sim = F.cosine_similarity(target_psd, psd)\n",
    "    new_cs.append(sim.item())\n",
    "    similarities.append(sim.item())\n",
    "print(similarities)\n",
    "print(new_cs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(new_sample_path)\n",
    "print(new_cs)\n",
    "print(len(new_sample_path), len(new_cs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "probilities = softmax(new_cs)\n",
    "print(probilities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_index = np.argmax(probilities)\n",
    "max_probability = probilities[max_index]\n",
    "print(\"最大概率及其索引:\", max_probability, max_index)\n",
    "\n",
    "remaining_probs = np.delete(probilities, max_index)\n",
    "\n",
    "normalized_remaining_probs = remaining_probs / remaining_probs.sum()\n",
    "\n",
    "random_index = np.random.choice(len(remaining_probs), p=normalized_remaining_probs)\n",
    "\n",
    "chosen_index = np.arange(len(probilities))[np.delete(np.arange(len(probilities)), max_index)][random_index]\n",
    "random_probability = probilities[chosen_index]\n",
    "\n",
    "print(\"轮盘赌选择的概率及其索引:\", random_probability, chosen_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_sample_path = new_sample_path[max_index]\n",
    "print(best_sample_path)\n",
    "other_sample_path = new_sample_path[random_index]\n",
    "print(other_sample_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_sample_cs = new_cs[max_index]\n",
    "other_sample_cs = new_cs[random_index]\n",
    "print(best_sample_cs, other_sample_cs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_sample_path = []\n",
    "new_sample_path.append(best_sample_path)\n",
    "new_sample_path.append(other_sample_path)\n",
    "print(new_sample_path)\n",
    "\n",
    "new_cs = []\n",
    "new_cs.append(best_sample_cs)\n",
    "new_cs.append(other_sample_cs)\n",
    "print(new_cs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = '/mnt/repo0/kyw/close-loop/loop_signal_result_1/fusion_loop_2'\n",
    "fusion_image_to_images(new_sample_path, 4, device, save_path, 128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2\n",
    "image_path_list = []\n",
    "label_list = []\n",
    "for image in sorted(os.listdir(save_path)):\n",
    "    image_path = os.path.join(save_path, image)\n",
    "    new_sample_path.append(image_path)\n",
    "    image_path_list.append(image_path)\n",
    "    file_name = os.path.splitext(image)[0]\n",
    "    label_list.append(file_name)\n",
    "print(new_sample_path)\n",
    "generate_and_save_eeg_for_all_images(model_path, image_path_list, save_path, device, label_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "similarities = []\n",
    "for eeg in sorted(os.listdir(save_path)):\n",
    "    if eeg.endswith('npy'):\n",
    "        eeg_path = os.path.join(save_path, eeg)\n",
    "        print(eeg_path)\n",
    "        file_name = os.path.splitext(eeg)[0]\n",
    "        eeg = np.load(eeg_path, allow_pickle=True)\n",
    "        selected_eeg = eeg[selected_channel_idxes, :]\n",
    "        psd, _ = psd_array_multitaper(selected_eeg, fs, adaptive=True, normalization='full', verbose=0)\n",
    "        psd = torch.from_numpy(psd.flatten())\n",
    "        psd = psd.unsqueeze(0)\n",
    "        sim = F.cosine_similarity(target_psd, psd)\n",
    "        new_cs.append(sim.item())\n",
    "        similarities.append(sim.item())\n",
    "        # average_signals = get_avg_signal(selected_eeg, file_name, 1)\n",
    "        # get_time_freq(average_signals, fs, file_name, 1)\n",
    "print(similarities)\n",
    "print(new_cs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "available_paths = [path for path in test_images_path if path not in processed_paths]\n",
    "print(len(available_paths))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_image_paths = random.sample(available_paths, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for sample_image_path in sample_image_paths:\n",
    "    new_sample_path.append(sample_image_path)\n",
    "print(new_sample_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_paths.update(sample_image_paths)\n",
    "print(len(processed_paths))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idxes = [test_images_path.index(path) for path in sample_image_paths]\n",
    "sample_eeg_paths = [eeg_paths[idx] for idx in idxes]\n",
    "similarities = []\n",
    "for sample_eeg_path in sample_eeg_paths:\n",
    "    print(sample_eeg_path)\n",
    "    sample_eeg = np.load(sample_eeg_path, allow_pickle=True)\n",
    "    selected_eeg = sample_eeg[selected_channel_idxes, :]\n",
    "    psd, _ = psd_array_multitaper(selected_eeg, fs, adaptive=True, normalization='full', verbose=0)\n",
    "    psd = torch.from_numpy(psd.flatten())\n",
    "    psd = psd.unsqueeze(0)\n",
    "    sim = F.cosine_similarity(target_psd, psd)\n",
    "    new_cs.append(sim.item())\n",
    "    similarities.append(sim.item())\n",
    "print(similarities)\n",
    "print(new_cs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(new_sample_path)\n",
    "print(new_cs)\n",
    "print(len(new_sample_path), len(new_cs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "probilities = softmax(new_cs)\n",
    "print(probilities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_index = np.argmax(probilities)\n",
    "max_probability = probilities[max_index]\n",
    "print(\"最大概率及其索引:\", max_probability, max_index)\n",
    "\n",
    "remaining_probs = np.delete(probilities, max_index)\n",
    "\n",
    "normalized_remaining_probs = remaining_probs / remaining_probs.sum()\n",
    "\n",
    "random_index = np.random.choice(len(remaining_probs), p=normalized_remaining_probs)\n",
    "\n",
    "chosen_index = np.arange(len(probilities))[np.delete(np.arange(len(probilities)), max_index)][random_index]\n",
    "random_probability = probilities[chosen_index]\n",
    "\n",
    "print(\"轮盘赌选择的概率及其索引:\", random_probability, chosen_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_sample_path = new_sample_path[max_index]\n",
    "print(best_sample_path)\n",
    "other_sample_path = new_sample_path[random_index]\n",
    "print(other_sample_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_sample_cs = new_cs[max_index]\n",
    "other_sample_cs = new_cs[random_index]\n",
    "print(best_sample_cs, other_sample_cs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_sample_path = []\n",
    "new_sample_path.append(best_sample_path)\n",
    "new_sample_path.append(other_sample_path)\n",
    "print(new_sample_path)\n",
    "\n",
    "new_cs = []\n",
    "new_cs.append(best_sample_cs)\n",
    "new_cs.append(other_sample_cs)\n",
    "print(new_cs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = '/mnt/repo0/kyw/close-loop/loop_signal_result_1/fusion_loop_3'\n",
    "fusion_image_to_images(new_sample_path, 4, device, save_path, 128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3\n",
    "image_path_list = []\n",
    "label_list = []\n",
    "for image in sorted(os.listdir(save_path)):\n",
    "    image_path = os.path.join(save_path, image)\n",
    "    new_sample_path.append(image_path)\n",
    "    image_path_list.append(image_path)\n",
    "    file_name = os.path.splitext(image)[0]\n",
    "    label_list.append(file_name)\n",
    "print(new_sample_path)\n",
    "generate_and_save_eeg_for_all_images(model_path, image_path_list, save_path, device, label_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "similarities = []\n",
    "for eeg in sorted(os.listdir(save_path)):\n",
    "    if eeg.endswith('npy'):\n",
    "        eeg_path = os.path.join(save_path, eeg)\n",
    "        print(eeg_path)\n",
    "        file_name = os.path.splitext(eeg)[0]\n",
    "        eeg = np.load(eeg_path, allow_pickle=True)\n",
    "        selected_eeg = eeg[selected_channel_idxes, :]\n",
    "        psd, _ = psd_array_multitaper(selected_eeg, fs, adaptive=True, normalization='full', verbose=0)\n",
    "        psd = torch.from_numpy(psd.flatten())\n",
    "        psd = psd.unsqueeze(0)\n",
    "        sim = F.cosine_similarity(target_psd, psd)\n",
    "        new_cs.append(sim.item())\n",
    "        similarities.append(sim.item())\n",
    "        # average_signals = get_avg_signal(selected_eeg, file_name, 1)\n",
    "        # get_time_freq(average_signals, fs, file_name, 1)\n",
    "print(similarities)\n",
    "print(new_cs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "available_paths = [path for path in test_images_path if path not in processed_paths]\n",
    "print(len(available_paths))\n",
    "sample_image_paths = random.sample(available_paths, 4)\n",
    "for sample_image_path in sample_image_paths:\n",
    "    new_sample_path.append(sample_image_path)\n",
    "print(new_sample_path)\n",
    "processed_paths.update(sample_image_paths)\n",
    "print(len(processed_paths))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idxes = [test_images_path.index(path) for path in sample_image_paths]\n",
    "sample_eeg_paths = [eeg_paths[idx] for idx in idxes]\n",
    "similarities = []\n",
    "for sample_eeg_path in sample_eeg_paths:\n",
    "    print(sample_eeg_path)\n",
    "    sample_eeg = np.load(sample_eeg_path, allow_pickle=True)\n",
    "    selected_eeg = sample_eeg[selected_channel_idxes, :]\n",
    "    psd, _ = psd_array_multitaper(selected_eeg, fs, adaptive=True, normalization='full', verbose=0)\n",
    "    psd = torch.from_numpy(psd.flatten())\n",
    "    psd = psd.unsqueeze(0)\n",
    "    sim = F.cosine_similarity(target_psd, psd)\n",
    "    new_cs.append(sim.item())\n",
    "    similarities.append(sim.item())\n",
    "print(similarities)\n",
    "print(new_cs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "probilities = softmax(new_cs)\n",
    "print(probilities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_index = np.argmax(probilities)\n",
    "max_probability = probilities[max_index]\n",
    "print(\"最大概率及其索引:\", max_probability, max_index)\n",
    "\n",
    "remaining_probs = np.delete(probilities, max_index)\n",
    "\n",
    "normalized_remaining_probs = remaining_probs / remaining_probs.sum()\n",
    "\n",
    "random_index = np.random.choice(len(remaining_probs), p=normalized_remaining_probs)\n",
    "\n",
    "chosen_index = np.arange(len(probilities))[np.delete(np.arange(len(probilities)), max_index)][random_index]\n",
    "random_probability = probilities[chosen_index]\n",
    "\n",
    "print(\"轮盘赌选择的概率及其索引:\", random_probability, chosen_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_sample_path = new_sample_path[max_index]\n",
    "print(best_sample_path)\n",
    "other_sample_path = new_sample_path[random_index]\n",
    "print(other_sample_path)\n",
    "best_sample_cs = new_cs[max_index]\n",
    "other_sample_cs = new_cs[random_index]\n",
    "print(best_sample_cs, other_sample_cs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_sample_path = []\n",
    "new_sample_path.append(best_sample_path)\n",
    "new_sample_path.append(other_sample_path)\n",
    "print(new_sample_path)\n",
    "\n",
    "new_cs = []\n",
    "new_cs.append(best_sample_cs)\n",
    "new_cs.append(other_sample_cs)\n",
    "print(new_cs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = '/mnt/repo0/kyw/close-loop/loop_signal_result_1/fusion_loop_4'\n",
    "fusion_image_to_images(new_sample_path, 4, device, save_path, 128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4\n",
    "image_path_list = []\n",
    "label_list = []\n",
    "for image in sorted(os.listdir(save_path)):\n",
    "    image_path = os.path.join(save_path, image)\n",
    "    new_sample_path.append(image_path)\n",
    "    image_path_list.append(image_path)\n",
    "    file_name = os.path.splitext(image)[0]\n",
    "    label_list.append(file_name)\n",
    "print(new_sample_path)\n",
    "generate_and_save_eeg_for_all_images(model_path, image_path_list, save_path, device, label_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "similarities = []\n",
    "for eeg in sorted(os.listdir(save_path)):\n",
    "    if eeg.endswith('npy'):\n",
    "        eeg_path = os.path.join(save_path, eeg)\n",
    "        print(eeg_path)\n",
    "        file_name = os.path.splitext(eeg)[0]\n",
    "        eeg = np.load(eeg_path, allow_pickle=True)\n",
    "        selected_eeg = eeg[selected_channel_idxes, :]\n",
    "        psd, _ = psd_array_multitaper(selected_eeg, fs, adaptive=True, normalization='full', verbose=0)\n",
    "        psd = torch.from_numpy(psd.flatten())\n",
    "        psd = psd.unsqueeze(0)\n",
    "        sim = F.cosine_similarity(target_psd, psd)\n",
    "        new_cs.append(sim.item())\n",
    "        similarities.append(sim.item())\n",
    "        # average_signals = get_avg_signal(selected_eeg, file_name, 1)\n",
    "        # get_time_freq(average_signals, fs, file_name, 1)\n",
    "print(similarities)\n",
    "print(new_cs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "available_paths = [path for path in test_images_path if path not in processed_paths]\n",
    "print(len(available_paths))\n",
    "sample_image_paths = random.sample(available_paths, 4)\n",
    "for sample_image_path in sample_image_paths:\n",
    "    new_sample_path.append(sample_image_path)\n",
    "print(new_sample_path)\n",
    "processed_paths.update(sample_image_paths)\n",
    "print(len(processed_paths))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idxes = [test_images_path.index(path) for path in sample_image_paths]\n",
    "sample_eeg_paths = [eeg_paths[idx] for idx in idxes]\n",
    "similarities = []\n",
    "for sample_eeg_path in sample_eeg_paths:\n",
    "    print(sample_eeg_path)\n",
    "    sample_eeg = np.load(sample_eeg_path, allow_pickle=True)\n",
    "    selected_eeg = sample_eeg[selected_channel_idxes, :]\n",
    "    psd, _ = psd_array_multitaper(selected_eeg, fs, adaptive=True, normalization='full', verbose=0)\n",
    "    psd = torch.from_numpy(psd.flatten())\n",
    "    psd = psd.unsqueeze(0)\n",
    "    sim = F.cosine_similarity(target_psd, psd)\n",
    "    new_cs.append(sim.item())\n",
    "    similarities.append(sim.item())\n",
    "print(similarities)\n",
    "print(new_cs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = '/mnt/repo0/kyw/close-loop/loop_signal_result_1/fusion_loop_5'\n",
    "new_sample_path = ['/mnt/repo0/kyw/images_set/test_images/00191_unicycle/unicycle_10s.jpg', '/mnt/repo0/kyw/close-loop/loop_signal_result_1/fusion_loop_4/128_1.jpg']\n",
    "fusion_image_to_images(new_sample_path, 4, device, save_path, 128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5\n",
    "image_path_list = []\n",
    "label_list = []\n",
    "for image in sorted(os.listdir(save_path)):\n",
    "    image_path = os.path.join(save_path, image)\n",
    "    new_sample_path.append(image_path)\n",
    "    image_path_list.append(image_path)\n",
    "    file_name = os.path.splitext(image)[0]\n",
    "    label_list.append(file_name)\n",
    "print(new_sample_path)\n",
    "generate_and_save_eeg_for_all_images(model_path, image_path_list, save_path, device, label_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "similarities = []\n",
    "for eeg in sorted(os.listdir(save_path)):\n",
    "    if eeg.endswith('npy'):\n",
    "        eeg_path = os.path.join(save_path, eeg)\n",
    "        print(eeg_path)\n",
    "        file_name = os.path.splitext(eeg)[0]\n",
    "        eeg = np.load(eeg_path, allow_pickle=True)\n",
    "        selected_eeg = eeg[selected_channel_idxes, :]\n",
    "        psd, _ = psd_array_multitaper(selected_eeg, fs, adaptive=True, normalization='full', verbose=0)\n",
    "        psd = torch.from_numpy(psd.flatten())\n",
    "        psd = psd.unsqueeze(0)\n",
    "        sim = F.cosine_similarity(target_psd, psd)\n",
    "        new_cs.append(sim.item())\n",
    "        similarities.append(sim.item())\n",
    "        # average_signals = get_avg_signal(selected_eeg, file_name, 1)\n",
    "        # get_time_freq(average_signals, fs, file_name, 1)\n",
    "print(similarities)\n",
    "print(new_cs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jiahua",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
